---
title: "Machine Learning for Unassessed Fisheries"
author: "Tyler Clavelle"
date: "3/27/2018"
output:
  html_document: default
---

```{r setup, include=FALSE}
# Chunk options
knitr::opts_chunk$set(
echo = F,
message = F,
warning = F,
cache = FALSE,
fig.align = "center"
)
# Packages
library(tidyverse)
# Results
load("../processed_data/training_testing_data.Rdata")
all_preds <- read_csv(file = "../processed_data/ml_predictions.csv")
# Figure Theme
theme_set(theme_minimal(base_size = 14, base_family = "Arial"))
```

## Objective
The objective of this analysis is to investigate the applicability of machine learning (ML) models to the estimation of fishery status. We examine the out-of-sample predictions and bias of several ML models trained on various subsets of the RAM stock assessment dataset. 

We use version 4.25 (with model fits) of the RAM database for this exercise. For the sake of comparison, we select only those stocks that were also used in Costello et al. (2016) and use the same independent variables in the development of our machine learning models.

## Methods

This analysis examines the predictions of three ML models:
  
  1. Random Forest (RF)
  2. Gradient Boosted Machine (GBM)
  3. Multivariate Adaptive Regression Splines (MARS)

### Training & Testing Data

```{r}
# Unnest the training and testing data for plotting
input_df <- models %>% 
  select(train_perc, split_type, split_metric, training) %>% 
  unnest() %>% 
  mutate(data = "training") %>% 
  bind_rows(models %>% 
  select(train_perc, split_type, split_metric, testing) %>% 
  unnest() %>% 
  mutate(data = "testing"))
```

A fundamental challenge with estimating the status of unnassessed fisheries is that they are widely believed to be both smaller and in worse shape than the fisheries in RAM that are used to train estimation models. Thus, we wanted to specifically examine the predictive accuracy of ML models under different assumptions about the distribution of fishery status ($\frac{B}{B_{MSY}}$) and size (mean lifetime catch) in the training and testing data. To accomplish this, we evaluate predictions for the following nine scenarios of data partioning:

+ Test on stocks with mean $\frac{B}{B_{MSY}}$ in the lower 20th, 40th, 60th, and 80th percentile
+ Test on stocks with mean lifetime catch in the lower 20th, 40th, 60th, and 80th percentile
+ Train on 80%, test on 20% 

Figures 1-3 show the resulting distributions of $\frac{B}{B_{MSY}}$ and catch included in the testing and training data for each scenario.

```{r, fig.cap="Figure 1"}
# Plot distributions of B/Bmsy and catch in each training/testing data split
input_df %>% 
  filter(split_type == 'status') %>% 
  ungroup() %>% 
  ggplot(aes(x = b_bmsy, fill = data)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("#375166", "#BE2A28")) +
  facet_grid(train_perc~split_metric) +
  labs(title = "Distribution of B/Bmsy for training and testing data",
       subtitle = "Data split by mean percentile of catch and B/Bmsy")
```

```{r, fig.cap="Figure 2"}
# Plot distributions of B/Bmsy and catch in each training/testing data split
input_df %>% 
  filter(split_type == 'status') %>% 
  ungroup() %>% 
  ggplot(aes(x = log10(tcbest), fill = data)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("#375166", "#BE2A28")) +
  facet_grid(train_perc~split_metric) +
  labs(title = "Distribution of catch for training and testing data",
       subtitle = "Data split by mean percentile of catch and B/Bmsy")
```

```{r, fig.cap="Figure 3"}
# Plot distributions of B/Bmsy and catch in each training/testing data split
input_df %>% 
  filter(split_type == 'random') %>%
  mutate(catch = log10(tcbest)) %>% 
  select(train_perc, data, b_bmsy, catch) %>%
  gather(key = 'metric', value = 'value', 4:5) %>% 
  ungroup() %>% 
  ggplot(aes(x = value, fill = data)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("#375166", "#BE2A28")) +
  facet_wrap(~metric, scales = "free") +
  labs(title = "Distribution of B/Bmsy and catch for training and testing data",
       subtitle = "80% training, 20% testing")
```

## Results

```{r}
# Filter out problem predictions
all_preds <- all_preds %>% 
  filter(pred <= 6 & pred > 0)
```

### Machine Learning Predictions

```{r, fig.cap="Figure 4"}
all_preds %>% 
  filter(split_type == 'random') %>% 
  ggplot() +
  geom_point(aes(x = b_bmsy, y = pred), alpha = 0.3) + 
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = 'red') +
  facet_grid(model~train_perc) + 
  labs(title = 'Out of sample B/Bmsy predictions for ML models',
       subtitle = '80% training, 20% testing',
       x = 'Observed',
       y = 'Predicted')
```

```{r, fig.cap="Figure 5"}
all_preds %>% 
  filter(split_type == 'status' & split_metric == 'catch') %>% 
  ggplot() +
  geom_point(aes(x = b_bmsy, y = pred), alpha = 0.3) + 
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = 'red') +
  facet_grid(model~train_perc) + 
  labs(title = 'Out of sample B/Bmsy predictions for ML models',
       subtitle = 'Data split by mean catch percentile (facet headers)',
       x = 'Observed',
       y = 'Predicted')
```

```{r, fig.cap="Figure 6"}
all_preds %>% 
  filter(split_type == 'status' & split_metric == 'b_bmsy') %>% 
  ggplot() +
  geom_point(aes(x = b_bmsy, y = pred), alpha = 0.3) + 
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = 'red') +
  facet_grid(model~train_perc) + 
  labs(title = 'Out of sample B/Bmsy predictions for ML models',
       subtitle = 'Data split by mean B/Bmsy percentile (facet headers)',
       x = 'Observed',
       y = 'Predicted')
```

### Comparison with PRM/Catch-MSY

Let's compare the predictions from our three ML models to B/Bmsy predictions obtained via the paired panel regression and catch-MSY method from Costello et al. (2016).

```{r}
# Read in results of GUM model
ram_gum <- read_csv(file = '../processed_data/ram_gum_results.csv')

### Combine predictions from two models
compare_df_random <- all_preds %>% 
  filter(split_type == 'random') %>% 
  select(model, train_perc, b_bmsy, pred) %>% 
  bind_rows(ram_gum %>%
              filter(year >= 1950) %>% 
              select(bdivbmsypref, BvBmsy) %>% 
              dplyr::rename(b_bmsy = bdivbmsypref,
                     pred   = BvBmsy) %>% 
              mutate(model = 'PRM-CMSY',
                     train_perc = list(unique(all_preds$train_perc[all_preds$split_type == 'random']))) %>% 
              unnest())

# Status split models
compare_df_status <- all_preds %>% 
  filter(split_type == 'status') %>% 
  select(model, train_perc, b_bmsy, pred) %>% 
  bind_rows(ram_gum %>%
              filter(year >= 1950) %>% 
              select(bdivbmsypref, BvBmsy) %>% 
              dplyr::rename(b_bmsy = bdivbmsypref,
                     pred   = BvBmsy) %>% 
              mutate(model = 'PRM-CMSY',
                     train_perc = list(unique(all_preds$train_perc[all_preds$split_type == 'status']))) %>% 
              unnest())
```


```{r, fig.cap="Figure 7"}
compare_df_random %>% 
  ggplot(aes(x = b_bmsy, y = pred)) +
  geom_point(alpha = 0.3) +
  coord_cartesian(xlim = c(0,5),
                  ylim = c(0,5)) + 
  geom_abline(intercept = 0, slope = 1, color = 'red', linetype = 2) +
  facet_wrap(~model) +
  labs(x = 'Observed',
       y = 'Predicted',
       title = 'B/Bmsy',
       subtitle = '80% training, 20% testing')

# ggsave(filename = "../figures/b_predict_compare.png", width = 6, height = 4)
```

```{r, fig.cap="Figure 8"}
compare_df_status %>% 
  # filter(model == 'RF') %>% 
  ggplot(aes(x = b_bmsy, y = pred)) +
  geom_point(alpha = 0.3) +
  coord_cartesian(xlim = c(0,5),
                  ylim = c(0,5)) + 
  geom_abline(intercept = 0, slope = 1, color = 'red', linetype = 2) +
  facet_grid(model~train_perc) +
  labs(x = 'Observed',
       y = 'Predicted',
       title = 'B/Bmsy',
       subtitle = 'Data split by mean catch percentile')

# ggsave(filename = "../figures/b_predict_compare.png", width = 6, height = 4)
```